{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the per cluster models**"
      ],
      "metadata": {
        "id": "1188mSlxAFg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import itertools\n",
        "\n",
        "train_df = pd.read_csv('train_data.csv')\n",
        "\n",
        "# Convert timestamp to datetime and extract time features\n",
        "train_df['timestamp'] = pd.to_datetime(train_df['timestamp'], unit='s')\n",
        "train_df['hour'] = train_df['timestamp'].dt.hour\n",
        "train_df['day_of_week'] = train_df['timestamp'].dt.dayofweek\n",
        "\n",
        "# Find unique IDs\n",
        "unique_ids = train_df['id'].unique()\n",
        "\n",
        "# Create a new DataFrame to store centroid locations for each user with time and day_of_week features\n",
        "centroid_data = pd.DataFrame(columns=['id', 'centroid_latitude', 'centroid_longitude', 'centroid_hour', 'centroid_day_of_week'])\n",
        "\n",
        "# Cluster Generation and Centroid Calculation for each user with time and day_of_week features\n",
        "for user_id in unique_ids:\n",
        "    user_data = train_df[train_df['id'] == user_id]\n",
        "\n",
        "    # Extract relevant features\n",
        "    features = ['latitude', 'longitude', 'hour', 'day_of_week']\n",
        "    X = user_data[features]\n",
        "\n",
        "    # Perform clustering (1 cluster)\n",
        "    kmeans = KMeans(n_clusters=1, random_state=42, n_init=1)\n",
        "    kmeans.fit(X)\n",
        "\n",
        "    # Calculate centroid\n",
        "    centroid = kmeans.cluster_centers_[0]\n",
        "    centroid_hour = int(round(centroid[2]))\n",
        "\n",
        "    # Append centroid data to the new DataFrame\n",
        "    centroid_data = pd.concat([centroid_data, pd.DataFrame({\n",
        "        'id': [user_id],\n",
        "        'centroid_latitude': [centroid[0]],\n",
        "        'centroid_longitude': [centroid[1]],\n",
        "        'centroid_hour': [centroid_hour],\n",
        "        'centroid_day_of_week': [int(round(centroid[3]))]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "# Display the new DataFrame with centroid locations for each user including time and day_of_week\n",
        "#print(centroid_data)"
      ],
      "metadata": {
        "id": "lwvh9i9xhejf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude 'id' column for clustering\n",
        "X = centroid_data.drop('id', axis=1)\n",
        "\n",
        "# Perform k-means clustering (5 clusters)\n",
        "kmeans = KMeans(n_clusters=5, random_state=42, n_init=1)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Add cluster labels to the centroid_data DataFrame\n",
        "centroid_data['cluster_label'] = kmeans.labels_\n",
        "\n",
        "# Display the updated DataFrame with cluster labels\n",
        "#print(centroid_data)"
      ],
      "metadata": {
        "id": "3vO5haHas92S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the user ID clusters\n",
        "#plt.figure(figsize=(8, 6))\n",
        "\n",
        "#for cluster_label in centroid_data['cluster_label'].unique():\n",
        "#    cluster = centroid_data[centroid_data['cluster_label'] == cluster_label]\n",
        "#    plt.scatter(cluster['centroid_longitude'], cluster['centroid_latitude'], label=f'Cluster {cluster_label}')\n",
        "\n",
        "#plt.xlabel('Longitude')\n",
        "#plt.ylabel('Latitude')\n",
        "#plt.title('Clustering of User IDs')\n",
        "#plt.legend()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "uqIijpQXtQrx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate pairwise distances within each cluster\n",
        "intracluster_distances = []\n",
        "for cluster_label in centroid_data['cluster_label'].unique():\n",
        "    cluster = centroid_data[centroid_data['cluster_label'] == cluster_label]\n",
        "    points = cluster[['centroid_latitude', 'centroid_longitude', 'centroid_hour', 'centroid_day_of_week']]\n",
        "    distances = pairwise_distances(points, metric='euclidean')\n",
        "    mean_distance = distances.mean()\n",
        "    intracluster_distances.append(mean_distance)\n",
        "\n",
        "# Create a DataFrame to store cluster labels and their intracluster distances\n",
        "cluster_distances = pd.DataFrame({\n",
        "    'Cluster': centroid_data['cluster_label'].unique(),\n",
        "    'Intracluster Distance': intracluster_distances\n",
        "})\n",
        "\n",
        "# Rank clusters based on intracluster distance (lower distance implies a better-defined cluster)\n",
        "cluster_distances = cluster_distances.sort_values(by='Intracluster Distance')\n",
        "\n",
        "# Display the ranked clusters based on intracluster distance\n",
        "print(cluster_distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPO-5Qvcuz5J",
        "outputId": "4c51ee6c-304a-4c8d-f78e-a259bc1c3a8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Cluster  Intracluster Distance\n",
            "3        2               0.000000\n",
            "4        1               0.000000\n",
            "1        0               0.214571\n",
            "2        4               0.326788\n",
            "0        3               0.867960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate pairwise distances between centroids of different clusters\n",
        "intercluster_distances = []\n",
        "cluster_labels = centroid_data['cluster_label'].unique()\n",
        "for label1, label2 in itertools.combinations(cluster_labels, 2):\n",
        "    cluster1 = centroid_data[centroid_data['cluster_label'] == label1]\n",
        "    centroid1 = cluster1[['centroid_latitude', 'centroid_longitude', 'centroid_hour', 'centroid_day_of_week']].mean()\n",
        "\n",
        "    cluster2 = centroid_data[centroid_data['cluster_label'] == label2]\n",
        "    centroid2 = cluster2[['centroid_latitude', 'centroid_longitude', 'centroid_hour', 'centroid_day_of_week']].mean()\n",
        "\n",
        "    distance = pairwise_distances([centroid1, centroid2], metric='euclidean')[0, 1]\n",
        "    intercluster_distances.append({'Cluster 1': label1, 'Cluster 2': label2, 'Intercluster Distance': distance})\n",
        "\n",
        "# Create a DataFrame to store intercluster distances\n",
        "intercluster_distances_df = pd.DataFrame(intercluster_distances)\n",
        "\n",
        "# Display the intercluster distances\n",
        "print(intercluster_distances_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HEx9xDCx01l",
        "outputId": "1b62d14c-56e1-487d-de60-3011e1404960"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Cluster 1  Cluster 2  Intercluster Distance\n",
            "0          3          0               1.206195\n",
            "1          3          4               2.223774\n",
            "2          3          2               2.852917\n",
            "3          3          1               6.675795\n",
            "4          0          4               1.018757\n",
            "5          0          2               4.000117\n",
            "6          0          1               6.578408\n",
            "7          4          2               5.002799\n",
            "8          4          1               6.656044\n",
            "9          2          1               7.688017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge cluster labels from centroid_data to the original DataFrame 'train_df'\n",
        "df = pd.merge(train_df, centroid_data[['id', 'cluster_label']], on='id', how='left')\n",
        "\n",
        "# Display the updated DataFrame with cluster labels\n",
        "#print(df)"
      ],
      "metadata": {
        "id": "hsnp-PBqzhTn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Create an empty dictionary to store models\n",
        "cluster_models = {}\n",
        "\n",
        "# Loop through each cluster label\n",
        "for cluster_label in df['cluster_label'].unique():\n",
        "    # Select data for the current cluster label\n",
        "    cluster_data = df[df['cluster_label'] == cluster_label]\n",
        "\n",
        "    # Features and target\n",
        "    X = cluster_data[['hour', 'day_of_week']]\n",
        "    y = cluster_data[['latitude', 'longitude']]  # Both latitude and longitude as target variables\n",
        "\n",
        "    # Train the RandomForestRegressor for each cluster\n",
        "    cluster_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    cluster_model.fit(X, y)\n",
        "\n",
        "    # Store the model corresponding to the cluster label in the dictionary\n",
        "    cluster_models[cluster_label] = cluster_model\n",
        "\n",
        "# Now 'cluster_models' dictionary contains trained models for each cluster label"
      ],
      "metadata": {
        "id": "cIlwPy-02MkI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure each cluster has its own model stored\n",
        "for cluster_label, cluster_model in cluster_models.items():\n",
        "    print(f\"Cluster Label: {cluster_label}\")\n",
        "    print(f\"Model: {cluster_model}\")\n",
        "    print(\"----------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4cSxVC-3aTk",
        "outputId": "41b26a5c-060c-470b-fe23-978f9b3b3d75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Label: 3\n",
            "Model: RandomForestRegressor(random_state=42)\n",
            "----------\n",
            "Cluster Label: 0\n",
            "Model: RandomForestRegressor(random_state=42)\n",
            "----------\n",
            "Cluster Label: 4\n",
            "Model: RandomForestRegressor(random_state=42)\n",
            "----------\n",
            "Cluster Label: 2\n",
            "Model: RandomForestRegressor(random_state=42)\n",
            "----------\n",
            "Cluster Label: 1\n",
            "Model: RandomForestRegressor(random_state=42)\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating the test file with latitude and longitude predictions made from the per cluster models**"
      ],
      "metadata": {
        "id": "njFNAZhSAWku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_df = pd.read_csv('test_data_redacted.csv')\n",
        "\n",
        "# Convert timestamp to datetime and extract time features\n",
        "test_df['timestamp'] = pd.to_datetime(test_df['timestamp'], unit='s')\n",
        "test_df['hour'] = test_df['timestamp'].dt.hour\n",
        "test_df['day_of_week'] = test_df['timestamp'].dt.dayofweek\n",
        "\n",
        "# Group test data with clusters based on user IDs\n",
        "test_df['cluster_label'] = test_df['id'].map(centroid_data.set_index('id')['cluster_label'])\n",
        "\n",
        "# Define a function to run the model for each cluster\n",
        "def run_model(cluster_data):\n",
        "    cluster_label = cluster_data['cluster_label'].iloc[0]\n",
        "    if cluster_label in cluster_models:\n",
        "        cluster_model = cluster_models[cluster_label]\n",
        "        X_predict = cluster_data[['hour', 'day_of_week']]\n",
        "        predicted_coordinates = cluster_model.predict(X_predict)\n",
        "        cluster_data['predicted_latitude'] = predicted_coordinates[:, 0]\n",
        "        cluster_data['predicted_longitude'] = predicted_coordinates[:, 1]\n",
        "    return cluster_data\n",
        "\n",
        "# Group by cluster label and apply the model to each cluster, preserving future behavior\n",
        "updated_df = test_df.groupby('cluster_label', group_keys=False).apply(run_model)\n",
        "\n",
        "# Display the updated DataFrame with predicted latitude and longitude\n",
        "#print(updated_df)\n",
        "\n",
        "predicted_coordinates_df = updated_df[['predicted_latitude', 'predicted_longitude']].copy()\n",
        "\n",
        "original_test_df = pd.read_csv('test_data_redacted.csv')\n",
        "per_cluster_preds = pd.concat([original_test_df, predicted_coordinates_df], axis=1)\n",
        "\n",
        "per_cluster_preds.to_csv('/content/per_cluster_predictions.csv', index=False)\n",
        "#print(per_cluster_preds)"
      ],
      "metadata": {
        "id": "4JkVIiUO3s9g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating the per user models**"
      ],
      "metadata": {
        "id": "GVV7uJdn0B1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Create an empty dictionary to store models\n",
        "user_models = {}\n",
        "\n",
        "# Group data by 'id'\n",
        "grouped = train_df.groupby('id')\n",
        "\n",
        "# Iterate through each group (unique 'id')\n",
        "for group_id, group_data in grouped:\n",
        "    # Extract features and target variables\n",
        "    X = group_data[['hour', 'day_of_week']]\n",
        "    y = group_data[['latitude', 'longitude']]\n",
        "\n",
        "    # Create a Random Forest regressor\n",
        "    user_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Fit the model\n",
        "    user_model.fit(X, y)\n",
        "\n",
        "    # Store the model in the dictionary with 'id' as key\n",
        "    user_models[group_id] = user_model"
      ],
      "metadata": {
        "id": "and87IIOCO3z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove cluster_label from test_df as it's not needed anymore\n",
        "test_df = test_df.drop(['cluster_label'], axis=1)\n"
      ],
      "metadata": {
        "id": "tgXlj8aRHn1C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to run the model for each ID\n",
        "def run_model_by_id(id_data):\n",
        "    id_value = id_data['id'].iloc[0]\n",
        "    if id_value in user_models:\n",
        "        user_model = user_models[id_value]\n",
        "        X_predict = id_data[['hour', 'day_of_week']]\n",
        "        predicted_coordinates = user_model.predict(X_predict)\n",
        "        id_data['predicted_latitude'] = predicted_coordinates[:, 0]\n",
        "        id_data['predicted_longitude'] = predicted_coordinates[:, 1]\n",
        "    return id_data\n",
        "\n",
        "# Group by ID and apply the model to each ID, preserving future behavior\n",
        "updated_df = test_df.groupby('id', group_keys=False).apply(run_model_by_id)\n",
        "\n",
        "# Display the updated DataFrame with predicted latitude and longitude\n",
        "#print(updated_df)\n",
        "\n",
        "# Create a DataFrame with predicted coordinates\n",
        "predicted_coordinates_df = updated_df[['predicted_latitude', 'predicted_longitude']].copy()\n",
        "\n",
        "# Merge predicted coordinates with the original test data\n",
        "original_test_df1 = pd.read_csv('test_data_redacted.csv')\n",
        "per_user_preds = pd.concat([original_test_df1, predicted_coordinates_df], axis=1)\n",
        "per_user_preds.to_csv('/content/per_user_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "XABfPHWCJjQO"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}